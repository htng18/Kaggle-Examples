{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - Keras: Core Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We study to classify the MNIST digits by using Keras\n",
    "# We use the core layers to build our model.\n",
    "# We demonstrate two examples. One is use three layers with \n",
    "# a fewer neutrons and another one is to use five layers. \n",
    "# The model with a larger number of layers and combined with \n",
    "# different activation functions can show a better performance.\n",
    "#\n",
    "# The data set can be downloaded from kaggle website as follows:\n",
    "# https://www.kaggle.com/apallekonda/keras-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=np.load('mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=data.f.y_train\n",
    "y_test=data.f.y_test\n",
    "X_train=data.f.x_train\n",
    "X_test=data.f.x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
    "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# The label set is required to transform as the one-hot encoding form\n",
    "from keras.utils import to_categorical\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cols=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(300,activation='tanh',input_shape=(n_cols,)))\n",
    "model.add(Dense(200,activation='tanh'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 297,710\n",
      "Trainable params: 297,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 4s - loss: 0.7225 - acc: 0.8010 - val_loss: 0.4285 - val_acc: 0.8808\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.3835 - acc: 0.8933 - val_loss: 0.3555 - val_acc: 0.8949\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.3266 - acc: 0.9074 - val_loss: 0.3165 - val_acc: 0.9109\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2893 - acc: 0.9184 - val_loss: 0.2863 - val_acc: 0.9179\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2655 - acc: 0.9240 - val_loss: 0.2749 - val_acc: 0.9192\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2535 - acc: 0.9264 - val_loss: 0.2599 - val_acc: 0.9232\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2391 - acc: 0.9315 - val_loss: 0.2560 - val_acc: 0.9250\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2257 - acc: 0.9343 - val_loss: 0.2443 - val_acc: 0.9273\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2144 - acc: 0.9374 - val_loss: 0.2347 - val_acc: 0.9322\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 2s - loss: 0.2042 - acc: 0.9396 - val_loss: 0.2219 - val_acc: 0.9353\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1931 - acc: 0.9444 - val_loss: 0.2132 - val_acc: 0.9368\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1917 - acc: 0.9442 - val_loss: 0.2131 - val_acc: 0.9374\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1843 - acc: 0.9451 - val_loss: 0.2102 - val_acc: 0.9395\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1828 - acc: 0.9462 - val_loss: 0.2034 - val_acc: 0.9398\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1769 - acc: 0.9480 - val_loss: 0.1978 - val_acc: 0.9427\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1738 - acc: 0.9479 - val_loss: 0.1970 - val_acc: 0.9382\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1689 - acc: 0.9496 - val_loss: 0.2003 - val_acc: 0.9402\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1655 - acc: 0.9516 - val_loss: 0.1976 - val_acc: 0.9412\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1714 - acc: 0.9490 - val_loss: 0.1996 - val_acc: 0.9417\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1617 - acc: 0.9528 - val_loss: 0.1957 - val_acc: 0.9408\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1622 - acc: 0.9508 - val_loss: 0.1858 - val_acc: 0.9442\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1532 - acc: 0.9547 - val_loss: 0.1855 - val_acc: 0.9449\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1468 - acc: 0.9568 - val_loss: 0.1857 - val_acc: 0.9442\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1427 - acc: 0.9572 - val_loss: 0.1773 - val_acc: 0.9477\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1463 - acc: 0.9562 - val_loss: 0.1780 - val_acc: 0.9472\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1503 - acc: 0.9555 - val_loss: 0.1812 - val_acc: 0.9461\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1474 - acc: 0.9555 - val_loss: 0.1870 - val_acc: 0.9434\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1475 - acc: 0.9565 - val_loss: 0.1774 - val_acc: 0.9463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22faffbcc50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_split=0.3,epochs=50,batch_size=100, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9728/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16952847801446916, 0.94899999999999995]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(350,activation='sigmoid',input_shape=(n_cols,)))\n",
    "model.add(Dense(250,activation='tanh'))\n",
    "model.add(Dense(150,activation='sigmoid'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 350)               274750    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               87750     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               37650     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 416,260\n",
      "Trainable params: 416,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 3s - loss: 1.8342 - acc: 0.5302 - val_loss: 1.2840 - val_acc: 0.7281\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.9389 - acc: 0.7928 - val_loss: 0.6870 - val_acc: 0.8423\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.5682 - acc: 0.8634 - val_loss: 0.4730 - val_acc: 0.8814\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.4172 - acc: 0.8928 - val_loss: 0.3783 - val_acc: 0.9001\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.3428 - acc: 0.9089 - val_loss: 0.3306 - val_acc: 0.9081\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2973 - acc: 0.9203 - val_loss: 0.2961 - val_acc: 0.9181\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2652 - acc: 0.9273 - val_loss: 0.2728 - val_acc: 0.9233\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2407 - acc: 0.9332 - val_loss: 0.2550 - val_acc: 0.9279\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2200 - acc: 0.9389 - val_loss: 0.2435 - val_acc: 0.9304\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.2063 - acc: 0.9410 - val_loss: 0.2278 - val_acc: 0.9354\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1922 - acc: 0.9465 - val_loss: 0.2164 - val_acc: 0.9391\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1769 - acc: 0.9494 - val_loss: 0.2097 - val_acc: 0.9389\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1664 - acc: 0.9520 - val_loss: 0.1992 - val_acc: 0.9431\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1563 - acc: 0.9554 - val_loss: 0.1935 - val_acc: 0.9447\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1489 - acc: 0.9574 - val_loss: 0.1890 - val_acc: 0.9477\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1409 - acc: 0.9591 - val_loss: 0.1825 - val_acc: 0.9474\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1349 - acc: 0.9608 - val_loss: 0.1818 - val_acc: 0.9461\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1277 - acc: 0.9636 - val_loss: 0.1738 - val_acc: 0.9491\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1181 - acc: 0.9673 - val_loss: 0.1690 - val_acc: 0.9498\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1147 - acc: 0.9672 - val_loss: 0.1683 - val_acc: 0.9511\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1074 - acc: 0.9698 - val_loss: 0.1618 - val_acc: 0.9536\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.1025 - acc: 0.9708 - val_loss: 0.1622 - val_acc: 0.9525\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0986 - acc: 0.9725 - val_loss: 0.1588 - val_acc: 0.9528\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0969 - acc: 0.9723 - val_loss: 0.1590 - val_acc: 0.9531\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0912 - acc: 0.9739 - val_loss: 0.1600 - val_acc: 0.9557\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0892 - acc: 0.9749 - val_loss: 0.1538 - val_acc: 0.9557\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0843 - acc: 0.9756 - val_loss: 0.1571 - val_acc: 0.9551\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0839 - acc: 0.9755 - val_loss: 0.1600 - val_acc: 0.9536\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0820 - acc: 0.9770 - val_loss: 0.1528 - val_acc: 0.9561\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0770 - acc: 0.9782 - val_loss: 0.1465 - val_acc: 0.9576\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0741 - acc: 0.9788 - val_loss: 0.1477 - val_acc: 0.9579\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0707 - acc: 0.9804 - val_loss: 0.1506 - val_acc: 0.9575\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0680 - acc: 0.9806 - val_loss: 0.1472 - val_acc: 0.9573\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0672 - acc: 0.9805 - val_loss: 0.1454 - val_acc: 0.9586\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0640 - acc: 0.9812 - val_loss: 0.1444 - val_acc: 0.9579\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0629 - acc: 0.9820 - val_loss: 0.1489 - val_acc: 0.9582\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0655 - acc: 0.9813 - val_loss: 0.1519 - val_acc: 0.9572\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0614 - acc: 0.9827 - val_loss: 0.1462 - val_acc: 0.9591\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0602 - acc: 0.9826 - val_loss: 0.1418 - val_acc: 0.9586\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0560 - acc: 0.9840 - val_loss: 0.1452 - val_acc: 0.9593\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0548 - acc: 0.9851 - val_loss: 0.1440 - val_acc: 0.9589\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0518 - acc: 0.9854 - val_loss: 0.1453 - val_acc: 0.9603\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 3s - loss: 0.0498 - acc: 0.9862 - val_loss: 0.1423 - val_acc: 0.9603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22fb008f5f8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_split=0.3, epochs=50,batch_size=100,callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9824/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13403828782271593, 0.96199999999999997]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
